2025-07-22 07:39:11,466 - INFO - === AetherNet Model Release Script ===
2025-07-22 07:39:11,467 - INFO - PyTorch: 2.7.1+cu126, Device: cuda, Model: net_g_185000.pth
2025-07-22 07:39:11,467 - INFO - 
[1/4] Loading and analyzing checkpoint
2025-07-22 07:39:11,592 - INFO - Scale: 2x, QAT: False, Validation sample: 154.png
2025-07-22 07:39:11,592 - INFO - 
[2/4] Initializing base model
2025-07-22 07:39:11,776 - INFO - Detected Architecture: aether_large
2025-07-22 07:39:11,799 - INFO - Base model loaded successfully.
2025-07-22 07:39:11,799 - INFO - Validating base model...
2025-07-22 07:39:15,323 - INFO - 
[3/4] Converting models to different precisions
2025-07-22 07:39:15,323 - INFO - 
>> Creating FP32 model
2025-07-22 07:39:15,323 - INFO - Attempt 1/3
2025-07-22 07:39:17,875 - INFO - ✅ Created optimized FP32 model
2025-07-22 07:39:17,956 - INFO - Saved FP32 model to: /home/phips/Documents/GitHub/aethernet-train/pretrains/2xaether_large/release/net_g_185000_aether_large_fp32.pth
2025-07-22 07:39:17,956 - INFO - Attempt 1/3
2025-07-22 07:39:23,508 - INFO - ✅ Exported and validated FP32 ONNX model
2025-07-22 07:39:23,508 - INFO - 
>> Creating FP16 model
2025-07-22 07:39:23,508 - INFO - Attempt 1/3
2025-07-22 07:39:26,549 - INFO - ✅ Created stable FP16 model
2025-07-22 07:39:26,615 - INFO - Saved FP16 model to: /home/phips/Documents/GitHub/aethernet-train/pretrains/2xaether_large/release/net_g_185000_aether_large_fp16.pth
2025-07-22 07:39:26,615 - INFO - Attempt 1/3
2025-07-22 07:39:33,897 - INFO - ✅ Exported and validated FP16 ONNX model
2025-07-22 07:39:33,897 - WARNING - 
Skipping INT8 conversion: The provided checkpoint is not from QAT.
2025-07-22 07:39:33,897 - INFO - 
[4/4] Conversion complete.
2025-07-22 07:39:33,897 - INFO - Results saved to: /home/phips/Documents/GitHub/aethernet-train/pretrains/2xaether_large/release
