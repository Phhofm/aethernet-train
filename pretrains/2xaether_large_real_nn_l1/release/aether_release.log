2025-07-22 07:40:47,347 - INFO - === AetherNet Model Release Script ===
2025-07-22 07:40:47,347 - INFO - PyTorch: 2.7.1+cu126, Device: cuda, Model: net_g_70000.pth
2025-07-22 07:40:47,347 - INFO - 
[1/4] Loading and analyzing checkpoint
2025-07-22 07:40:47,472 - INFO - Scale: 2x, QAT: False, Validation sample: 154.png
2025-07-22 07:40:47,472 - INFO - 
[2/4] Initializing base model
2025-07-22 07:40:47,618 - INFO - Detected Architecture: aether_large
2025-07-22 07:40:47,640 - INFO - Base model loaded successfully.
2025-07-22 07:40:47,641 - INFO - Validating base model...
2025-07-22 07:40:50,784 - INFO - 
[3/4] Converting models to different precisions
2025-07-22 07:40:50,784 - INFO - 
>> Creating FP32 model
2025-07-22 07:40:50,784 - INFO - Attempt 1/3
2025-07-22 07:40:53,348 - INFO - ✅ Created optimized FP32 model
2025-07-22 07:40:53,428 - INFO - Saved FP32 model to: /home/phips/Documents/GitHub/aethernet-train/pretrains/2xaether_large_real_nn_l1/release/net_g_70000_aether_large_fp32.pth
2025-07-22 07:40:53,428 - INFO - Attempt 1/3
2025-07-22 07:40:57,885 - INFO - ✅ Exported and validated FP32 ONNX model
2025-07-22 07:40:57,885 - INFO - 
>> Creating FP16 model
2025-07-22 07:40:57,885 - INFO - Attempt 1/3
2025-07-22 07:40:59,974 - INFO - ✅ Created stable FP16 model
2025-07-22 07:41:00,041 - INFO - Saved FP16 model to: /home/phips/Documents/GitHub/aethernet-train/pretrains/2xaether_large_real_nn_l1/release/net_g_70000_aether_large_fp16.pth
2025-07-22 07:41:00,041 - INFO - Attempt 1/3
2025-07-22 07:41:04,128 - INFO - ✅ Exported and validated FP16 ONNX model
2025-07-22 07:41:04,128 - WARNING - 
Skipping INT8 conversion: The provided checkpoint is not from QAT.
2025-07-22 07:41:04,128 - INFO - 
[4/4] Conversion complete.
2025-07-22 07:41:04,128 - INFO - Results saved to: /home/phips/Documents/GitHub/aethernet-train/pretrains/2xaether_large_real_nn_l1/release
