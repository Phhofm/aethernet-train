name = "2xaether_tiny_finetune"
model_type = "image"
scale = 2
use_amp = false
bfloat16 = false
fast_matmul = true

[datasets.train]
type = "paired"
dataroot_gt = '/home/phips/Documents/dataset/PDM/OSISRD/v3/hr'
dataroot_lq = '/home/phips/Documents/dataset/PDM/OSISRD/v3/x2'
patch_size = 128 # from 64 to 128, because it hit its sealing with 64 and could not progress further
batch_size = 8

[datasets.val]
name = "val"
type = "paired"
dataroot_gt = '/home/phips/Documents/dataset/PDM/OSISRD/v3/validation/hr'
dataroot_lq = '/home/phips/Documents/dataset/PDM/OSISRD/v3/validation/x2'

[val]
val_freq = 5000
[val.metrics.psnr]
type = "calculate_psnr"
[val.metrics.ssim]
type = "calculate_ssim"
[val.metrics.dists]
type = "calculate_dists"
better = "lower"
[val.metrics.topiq]
type = "calculate_topiq"

[path]
pretrain_network_g = '/home/phips/Documents/GitHub/aethernet-train/neosr/experiments/2xaether_tiny/models/net_g_210000.pth' # could not progress / peak this model. Ill try with patch 192 instead of 64 and see if it can 

[network_g]
type = "aether_tiny"
#type = "aether_small"
#type = "aether_medium"
#type = "aether_large"

[train]
enable_qat = false # the non-qat pretrain, best quality and stability for training from scratch
grad_clip = true # even in FP32, certain data patches can cause the loss to spike momentarily. This hepls protect against exploding gradients.
ema = 0.999 # use this for fp32 pretrain

[train.optim_g]
type = "adamw"
lr = 1e-4
betas = [ 0.9, 0.99 ]
weight_decay = 0

[train.pixel_opt]
type = "L1Loss"
loss_weight = 1.0
reduction = "mean"

[train.scheduler]
type = "MultiStepLR"
milestones = [ 400000, 600000, 800000, 900000 ]
gamma = 0.5

[logger]
total_iter = 1000000
save_checkpoint_freq = 5000
use_tb_logger = true
